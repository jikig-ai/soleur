# Brainstorm: Self-Iterating Test-Fix Loop

**Date:** 2026-02-22
**Status:** Active
**Related:** #216 (Self-iterating implementation loop against test suites)

## What We're Building

A new skill (`test-fix-loop`) that implements an autonomous implement-test-fix loop. After code is written, the skill runs the test suite, analyzes failures, applies fixes, and repeats until all tests pass or a termination condition is met. This is a recovery mechanism for when implementation produces unexpected test failures -- not a replacement for RED/GREEN/REFACTOR discipline.

Motivated by Claude Code Insights: 15 "buggy_code" friction events across 139 sessions, 20 feature implementations and 10 bug fixes running as single-pass workflows.

## Why This Approach

**Skill over command or /work extension because:**

- Keeps `/soleur:work` lean (already 500+ lines)
- Composable: `/soleur:work` can delegate to it, or it can run standalone
- Follows the pattern of `atdd-developer` (skill with test-related workflow)
- Skills are flat under `skills/<name>/SKILL.md` -- no loader changes needed

**Fully autonomous (no per-iteration approval) because:**

- The existing `atdd-developer` skill already covers human-gated TDD
- This skill fills a different niche: autonomous batch recovery
- Termination conditions (max iterations, regression detection) provide safety
- Users invoke this explicitly -- the consent is the invocation itself

## Key Decisions

1. **Placement:** New skill at `skills/test-fix-loop/SKILL.md`
2. **Autonomy:** Fully autonomous. Stops on success, max iterations, or regression. No per-iteration approval.
3. **Context management:** Truncate + summarize test output. Only pass failure summaries (test name + error message) to fix logic, not full stack traces. ~80% token reduction.
4. **Fix isolation:** Git stash per attempt. Stash the fix, run tests, pop if green, drop if red. Only commit when all tests pass. Clean history.
5. **Circular detection:** Failure count trajectory as primary signal (if not monotonically decreasing, flag regression). Test name set comparison as secondary circular detector.
6. **Sub-agent strategy:** Batch failures by file/module (max 5 clusters), not one agent per error. Same clustering pattern as `/soleur:work` Tier B.
7. **Test runner discovery:** Auto-detect from project files (package.json, Makefile, Cargo.toml, etc.). Fallback to asking the user.
8. **Max iterations:** 5 (configurable). Per-invocation, not per-failure.

## Workflow

```text
1. DETECT test runner (auto-detect or ask)
2. RUN full test suite
3. IF all pass: done (exit successfully)
4. PARSE failures into summary (test name + error message only)
5. CLUSTER failures by file/module (max 5 groups)
6. FOR EACH cluster: analyze root cause, propose fix
7. STASH current state
8. APPLY all fixes
9. RUN full test suite
10. IF all pass: drop stash, commit, done
11. IF failures decreased: record progress, continue (goto 4)
12. IF failures increased OR same tests recurring: drop fixes, pop stash, stop with diagnostic report
13. IF max iterations reached: stop with diagnostic report
```

## Termination Conditions

| Condition | Action |
|-----------|--------|
| All tests pass | Exit successfully. Commit fixes. |
| Max iterations reached (default: 5) | Stop. Write diagnostic report. Ask for guidance. |
| Failure count not decreasing | Stop. Regression detected. Pop stash to revert last attempt. Report. |
| Same test name set appears twice | Stop. Circular fix detected. Report what was tried. |

## CTO Risk Assessment Summary

| Risk | Severity | Mitigation |
|------|----------|------------|
| Context window exhaustion | HIGH | Truncated summaries only (~80% reduction) |
| Cascading bad fixes | HIGH | Git stash isolation; failure trajectory detection |
| Circular fix detection false negatives | MEDIUM | Combined trajectory + test name set tracking |
| Sub-agent token cost | MEDIUM | Batch by module (max 5 clusters), not per-error |
| User loses control | MEDIUM | Explicit invocation = consent; termination conditions provide safety |

## Integration Points

- `/soleur:work` Phase 2: After task loop, if tests fail, delegate to this skill
- `/soleur:one-shot`: Can replace manual fix steps with this skill
- `/soleur:review`: Review findings could feed into fix targets
- Standalone: `test-fix-loop` can be invoked directly for any codebase

## Resolved Questions

- **Placement?** Skill, not command or /work extension
- **Autonomy level?** Fully autonomous with termination conditions
- **Context budget?** Truncated summaries, not full test output
- **Fix isolation?** Git stash per attempt
- **Test runner?** Auto-detect from project files
- **Sub-agent granularity?** Batch by module, max 5 clusters
